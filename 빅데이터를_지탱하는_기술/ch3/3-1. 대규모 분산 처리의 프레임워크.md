# 구조화 데이터와 비구조화 데이터
스키마(테이블의 커럼명, 데이터형, 테이블간의 관계등을 의미)가 명확하게 정의된 데이터를 구조화된 데이터라고 하며
기존의 데이터 웨어하우스에서는 항상 구조화된 데이터로 축적하는 것이 일반적이었다.

빅데이터 시대의 핵심은 기존처럼 정형화된 데이터만이 아니라 이미지, 동영상 같이 비정형화된 데이터가 증가하고
이 또한 분석이 필요해졌다는 사실이다. 하지만 비정형화된 데이터는 SQL로 제대로 집계할 수 없다.

> CSV, JSON과 같은 데이터는 서식은 있지만 커럼 수나 데이터형이 명확하지 않은 스키마리스 데이터라고 한다.

NoSQL 데이터베이스가 이러한 스키마리스 데이터에 대응하고 있다.
이러한 다양한 형태의 데이터를 우선 데이터 레이크에 저장한 후, 분석하기 용이하게 분산 스토리지에 옮기는 파이프라인이 필요하다.

데이터 레이크에서 데이터를 가공하는 과정에서 비정형 데이터의 스키마를 정의하고 구조화된 데이터로 변환함으로써 다른 데이터와 마찬가지로 분석할 수 있게 되는 것이다.

이 때 MPP 데이터베이스 즉, 데이터 웨어하우스 같이 이미 하드웨어가 구축된 스토리지 서비스를 쓸 수도 있고, Hadoop 내에서 열지향스토리지 형식을 지정하여 그 곳에 데이터를 저장할 수도 있다.

여러 형태의 데이터들을 구조화된 데이터로 변경하여 SQL로 집계할 수 있는 것에 집중하고, 특별히 테이블간의 조인은 하지 않는다.(이러한 조인은 데이터 마트를 만들 때 고려한다.)

Hadoop에서 사용할 수 있는 열지향 스토리지에는 대표적으로 두 개가 있다.

Apache ORC는 구조화 데이터를 위한 열지향 스토리지로 처음에 스키마를 정한 후 데이터를 저장한다.
Apache Parquet는 스키마리스에 가까운 데이터 구조로 되어있어 json 같은 데이터도 그대로 저장할 수 있다.

이 때 비구조화 데이터도 열지향 스토리지로 변환하는 과정을 거쳐야 하는데, 이 때 사용되는 것이 Hadoop과 Spark이다.

# Hadoop(분산 데이터 처리의 공통 플랫폼)
Hadoop은 현재 빅데이터를 대표하는 시스템으로 알려져있다. 단일 소프트웨어가 아니라 분산 시스템을 구성하는 다수의 소프트웨어로 이루어진 집합체다.

기본 구성요소는 분산파일 시스템인 HDFS, 리소스 관리자인 YARN, 분산 데이터 처리를 담당하는 MapReduce가 있다.
여기에 쿼리엔진으로 Hive, Impala가 있고, 더 발전하여 (Hadoop과는 독립적인) 쿼리엔진과 분산 데이터처리가 동시에 가능한 Apache Spark, Flink 등이 존재한다.

모든 분산 시스템이 Hadoop의 모든 시스템을 사용하는 것이 아니라, 상황에 따라 선별적으로 사용한다.
Hadoop에서 처리되는 데이터 대부분은 분산 파일 시스템에 저장된다. 이는 파일서버와 같은 존재이다.

이 때 CPU, 메모리 등의 계산 리소스는 리소스 매니저에서 관리한다. 리소스 관리자인 YARN을 통해 애플리케이션 실행의 우선순위를 결정할 수 있다.

분산 데이터를 처리하는 대표적인 것으로 MapReduce가 있다. 
그리고 쿼리 언어에 의한 데이터 집계가 목적이라면 그것을 위한 쿼리 엔진인 Hive를 사용한다.

기본적으로 Hadoop 시스템 내의 MapReduce나 Hive는 빠르며 대량 배치처리에 적합하지만 가벼운 데이터 처리에는 적합하지 않다.

이를 보완하기 위해 Tez가 등장했다. Tez는 Hive를 가속화하기 위해 등장했으며 MapReduce의 단점을 보완하여 고속화를 실현했다.

가령 MapReduce에서는 스테이지가 끝날 때까지 다음 처리를 진행할 수 없었지만, 
Tez에서는 스테이지의 종료를 기다리지 않고 처리가 끝난 데이터를 차례대로 후속처리에 전달함으로써 쿼리 전체의 실행시간을 단축한다.

Hive는 Tez에서도 동작하므로 Hive on Tez라고 부린다. 대화형 쿼리엔진인 Impala, Presto도 등장했다.
MapReduce와 Tez는 장시간의 배치 처리를 가정해 한정된 리소스를 유용하게 활용한다.

# Spark(인메모리 형의 고속 데이터 처리)
Spark는 MapReduce를 대체하여 MapReduce보다 더 효율적인 데이터 처리를 실현하는 것으로 등장했다.
스파크의 특징은 대량의 메모리를 활용하여 고속화를 실현하는 것이다.

실행중에 많은 메모리가 필요하지만 실행시간이 단축된다.
Spark는 Hadoop을 대체한 것이 아니라 데이터 처리인 MapReduce를 대체한 것이다.
Spark의 특징은 실행에 자바 런타임이 필요하지만, 실행되는 데이터 처리는 스크립트 언어를 사용할 수 있다.
